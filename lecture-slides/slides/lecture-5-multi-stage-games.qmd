---
subtitle: "Lecture 5 - Multi-stage Games"
---

# Multi-stage Games {background-color="#00539b"}

## Multi-stage games: overview

::: {.callout-note}

How commitment in earlier stages changes equilibrium behaviour in later stages.

:::

- So far:
  - Mostly simultaneous-move games
  - Briefly: two-stage game (@shyIndustrialOrganizationTheory1995 model in Lecture 4)

- Today:
  - Stackelberg quantity leadership
  - Strategic delegation [@vickersDelegationTheoryFirm1985]

## Learning objectives

By the end of this lecture you should be able to:

1. Define subgame perfect Nash equilibrium and apply backward induction in finite games
2. Derive and interpret the Stackelberg equilibrium under quantity leadership
3. Set up and solve a two-stage delegation game (contract stage + product-market subgame)
4. Compare equilibrium outcomes and welfare across Cournot, Stackelberg, and delegation

## Example: Ultimatum game

- Setup
  - Stage 1: Player 1 proposes a share $x$ for Player 2 in splitting \$10 (with $0 \leq x \leq 10$)
  - Stage 2: Player 2 observes $x$ and accepts the proposal (`A`) or rejects it (`R`)
  - Players' payoffs:
    $$
    u_1(x,A)=10-x \qquad u_2(x,A)=x \qquad u_1(x,R)=u_2(x,R)=0
    $$


## Ultimatum game: Solution

- Solution by backward induction
  - Player 2 accepts any offer $x > 0$; for $x = 0$, they are indifferent between accepting and rejecting
  - Player 1 offers Player 2 as little as possible and keeps the largest possible remainder
  - Backward-induction outcome: $(0, A)$

## Solution concept: subgame perfect equilibrium

- A strategy profile is a **subgame perfect Nash equilibrium (SPNE)** if it induces a Nash equilibrium in every subgame

- Operationally (finite horizon):
  - Solve from the last stage backward (backward induction)

::: {.callout-important}
## Commitment logic

A credible first-stage choice is observed by later movers and shifts their best responses. The payoff function is unchanged — only equilibrium strategies change.
:::


# Extensive-form foundations {background-color="#00539b"}

## Games with complete and perfect information: extensive form

- Dynamic games can be represented in **extensive form**

::: {.callout-note}
## Extensive form (definition)

An extensive-form game specifies:

1. which player moves at each decision point (and when)
2. each player's payoff for every possible terminal history (outcome)
3. the available actions at each decision node
4. what the acting player knows about previous moves when choosing
:::

## Game tree: basic components

- Simple dynamic games can be illustrated with a **game tree**

- Components:
  - **Decision nodes**: points where a player chooses
  - **Branches**: feasible actions
  - **Terminal nodes**: outcomes/payoffs

- Example structure (generic two-stage game):

```text
Player 1
|- L -> Player 2: l -> (a1,a2), r -> (b1,b2)
`- R -> Player 2: l -> (c1,c2), r -> (d1,d2)
```

## Game tree: validity conditions

- A valid game tree has:
  - a unique starting point (**root**)
  - a unique predecessor for each non-root node
  - no cycles

::: {.callout-warning}
## Why this matters

If there are cycles or nodes with multiple predecessors, the object is not a tree and standard backward-induction logic is not directly applicable.
:::

## Strategy in a dynamic game (pure strategy)

::: {.callout-note}
## Definition (pure strategy)

A (pure) strategy is a **complete contingent plan**: it specifies an action at every decision node (or, with imperfect information, at every information set) where the player may move.
:::

- Key implication:
  - A strategy must specify actions even at nodes that may not be reached on the equilibrium path

## Example: strategies induced by a game tree

- Consider:

```text
Player 1 chooses L or R
If L: Player 2 chooses l or r -> (a1,a2) or (b1,b2)
If R: Player 2 chooses l or r -> (c1,c2) or (d1,d2)
```

- Player 1 has one decision node:
  - $s_1^1=(L)$
  - $s_1^2=(R)$

- Player 2 has two decision nodes, so 4 pure strategies:
  - $s_2^1=(l|L,\ l|R)$
  - $s_2^2=(l|L,\ r|R)$
  - $s_2^3=(r|L,\ l|R)$
  - $s_2^4=(r|L,\ r|R)$

## Extensive form to normal form (example)

|  | $s_2^1=(l|L,l|R)$ | $s_2^2=(l|L,r|R)$ | $s_2^3=(r|L,l|R)$ | $s_2^4=(r|L,r|R)$ |
|---|---|---|---|---|
| $s_1^1=(L)$ | $(a_1,a_2)$ | $(a_1,a_2)$ | $(b_1,b_2)$ | $(b_1,b_2)$ |
| $s_1^2=(R)$ | $(c_1,c_2)$ | $(d_1,d_2)$ | $(c_1,c_2)$ | $(d_1,d_2)$ |

::: {.callout-important}
## Exam tip

When converting a game tree to normal form, count strategies by counting **complete plans**, not just actions on the equilibrium path.
:::

## Entry game: extensive form

- Stage 1: entrant chooses **Enter** or **Stay out**
- Stage 2 (if entry): incumbent chooses **Fight** or **Accommodate**

- Payoffs (as in the original example):
  - Stay out $\rightarrow (0,2)$
  - Enter + Fight $\rightarrow (-3,-1)$
  - Enter + Accommodate $\rightarrow (2,1)$

- Strategies:
  - Entrant: $(\text{Stay out})$, $(\text{Enter})$
  - Incumbent: $(\text{Fight if entry})$, $(\text{Accommodate if entry})$

## Entry game: Nash equilibria in normal form

| Entrant / Incumbent | Fight (if entry) | Accommodate (if entry) |
|---|---:|---:|
| Stay out | $(0,2)$ | $(0,2)$ |
| Enter | $(-3,-1)$ | $(2,1)$ |

- Pure-strategy Nash equilibria:
  1. $(\text{Stay out},\ \text{Fight if entry})$
  2. $(\text{Enter},\ \text{Accommodate if entry})$

- Question:
  - Are both equilibria equally plausible in a dynamic setting?

## Backward induction: credibility and equilibrium selection

- The equilibrium $(\text{Stay out},\ \text{Fight if entry})$ relies on a **non-credible threat**

- Backward induction logic:
  - If entry occurs, the incumbent prefers **Accommodate** to **Fight** ($1>-1$)
  - Anticipating this, the entrant chooses **Enter** ($2>0$)

::: {.callout-important}
## Backward-induction outcome (entry game)

$(\text{Enter},\ \text{Accommodate if entry})$
:::

- Backward induction is applicable to finite dynamic games with perfect information

## Backward induction: generic procedure (two-stage game)

- Stage 1: Player 1 chooses $a_1 \in A_1$
- Stage 2: Player 2 observes $a_1$ and chooses $a_2 \in A_2$
- Payoffs: $u_1(a_1,a_2)$ and $u_2(a_1,a_2)$

- Procedure:
  1. Solve Player 2's problem for each history $a_1$:
     - choose $a_2$ to maximise $u_2(a_1,a_2)$
     - define the reaction function $R_2(a_1)$ (if unique)
  2. Substitute into Player 1's payoff and solve:
     - choose $a_1$ to maximise $u_1(a_1,R_2(a_1))$
  3. The equilibrium path is $\big(a_1^\ast, R_2(a_1^\ast)\big)$

::: {.callout-note}
## Bridge to Stackelberg

The Stackelberg model is exactly this two-stage structure: the follower's best response is solved first, then the leader optimises anticipating that response.
:::


# Stackelberg competition {background-color="#00539b"}

## Stackelberg model: Structure

- Two stages, two firms:

  1. Leader chooses $q_1$
  2. Follower observes $q_1$ and chooses $q_2$

- Demand and costs:
  - Inverse demand: $p(Q)=A-Q$ with $Q=q_1+q_2$
  - Marginal cost: $c$ (parameter)

## Follower best response

- Follower profit given $q_1$:

$$
\pi_2(q_2;q_1) = (A-q_1-q_2-c)q_2
$$

- Best response:

$$
BR_2(q_1)=\frac{A-c-q_1}{2}
$$

::: {.callout-note}
## Strategic substitutes (quantities)

Quantities are strategic substitutes: when the rival increases output, my best-response output decreases (downward-sloping best response).
:::

## Stackelberg model: leader choice

- Substitute follower response into leader profit:

$$
\pi_1(q_1) = (A-q_1-BR_2(q_1)-c)q_1
$$

- Equilibrium (identical costs):
  - $q_1^S=\frac{A-c}{2}$
  - $q_2^S=\frac{A-c}{4}$

::: {.callout-important}
## First-mover advantage

The leader commits to a higher $q_1$, anticipating that the follower reduces $q_2$.
:::

::: {.notes}
**Full FOC derivation (leader):**

Substitute $BR_2(q_1)=\frac{A-c-q_1}{2}$ into leader profit:

$$\pi_1(q_1)=\left(A-q_1-\frac{A-c-q_1}{2}-c\right)q_1=\left(\frac{A-c}{2}-\frac{q_1}{2}\right)q_1=\frac{A-c}{2}q_1-\frac{1}{2}q_1^2$$

First-order condition:

$$\frac{\partial\pi_1}{\partial q_1}=\frac{A-c}{2}-q_1=0\quad\Rightarrow\quad q_1^S=\frac{A-c}{2}$$

Then follower output:

$$q_2^S=BR_2(q_1^S)=\frac{A-c-\frac{A-c}{2}}{2}=\frac{A-c}{4}$$
:::

## Stackelberg v Cournot: equilibrium outcomes

| Outcome | Stackelberg | Cournot |
|---|---:|---:|
| Firm 1 output | $q_1^S=\frac{A-c}{2}$ | $q_1^C=\frac{A-c}{3}$ |
| Firm 2 output | $q_2^S=\frac{A-c}{4}$ | $q_2^C=\frac{A-c}{3}$ |
| Aggregate output | $Q^S=\frac{3(A-c)}{4}$ | $Q^C=\frac{2(A-c)}{3}$ |
| Price | $p^S=\frac{A+3c}{4}$ | $p^C=\frac{A+2c}{3}$ |
| Firm 1 profit | $\pi_1^S=\frac{(A-c)^2}{8}$ | $\pi_1^C=\frac{(A-c)^2}{9}$ |
| Firm 2 profit | $\pi_2^S=\frac{(A-c)^2}{16}$ | $\pi_2^C=\frac{(A-c)^2}{9}$ |


## Stackelberg model: remarks

- Comparative statics questions:

  - What changes when marginal costs are asymmetric?

  - What changes if the timing is endogenous (announcement/commitment issues)?

## Numerical example ($A=10$, $c=1$)

- Parameters: $A=10$ (demand intercept), $c=1$ (marginal cost)

- Stackelberg outcomes:
  - $q_1^S=\frac{A-c}{2}=4.5$; $q_2^S=\frac{A-c}{4}=2.25$
  - $Q^S=6.75$; $p^S=A-Q^S=3.25$
  - $\pi_1^S=(p^S-c)q_1^S=10.125$

- Cournot benchmark:
  - $\pi_1^C=\frac{(A-c)^2}{9}=9$

::: {.callout-important}
## Concrete comparison

With $A=10$, $c=1$: $\pi_1^S=10.125 > \pi_1^C=9$ (first-mover advantage).
:::

## Welfare comparison (to Cournot)

- With linear demand $p=A-Q$ and constant marginal cost $c$:

  - Higher total output implies lower price $\Rightarrow$ higher consumer surplus (CS)
  - Stackelberg yields $Q^S>\,Q^C$ (hence $CS^S>CS^C$)

- Total surplus changes because:
  - CS rises with $Q$
  - profits can rise for the leader and fall for the follower relative to Cournot


#  @vickersDelegationTheoryFirm1985 : Strategic delegation  {background-color="#00539b"}

## Delegation: Economic idea

- Firms may delegate output choice to managers with objectives that differ from pure profit maximisation

- Delegation instrument:
  - an incentive parameter $\theta_i$ written into the manager’s contract

## Delegation (Vickers): model

- Cournot oligopoly with $n$ firms: $i=1,\dots,n$

- Manager of firm $i$ maximises:

$$
M_i=\pi_i+\theta_i q_i
$$

where $\pi_i=p(Q)q_i-cq_i$ and $Q=\sum_i q_i$

- Equivalently: $M_i = p(Q)q_i - (c-\theta_i)q_i$ — so $\theta_i$ acts like a reduction in the manager's effective marginal cost


## Commitment assumption

For delegation to affect rivals' behaviour, contracts must be:

- observable (rivals see $\theta_i$)

- binding (owners cannot override managers after $\theta_i$ is set)


## Delegation: Triopoly exercise (setup)

- Cournot triopoly: $i=1,2,3$
- Demand: $p(Q)=A-Q$
- Identical marginal costs: $c$
- Managers: $\theta_i \ge 0$

- Task:
  - Solve the $\theta$-setting game given the induced Cournot equilibrium in $(q_1,q_2,q_3)$

## Delegation: triopoly solution steps

- **Step 1 (product-market subgame)**: given $(\theta_1,\theta_2,\theta_3)$, managers play Cournot and determine $q_i^*(\theta)$

- **Step 2 (contract stage)**: each owner chooses $\theta_i$ to maximise own profit $\pi_i(\theta_i;\theta_{-i})$

- **Step 3 (equilibrium incentives)**: solve the system of best responses in $\theta$
  - in symmetry: $\theta_1=\theta_2=\theta_3=\hat{\theta}$

::: {.callout-important}
## Exam template

Two-stage delegation problems are solved exactly like Stackelberg: solve the quantity subgame first, then solve the incentive-setting stage.
:::

## Triopoly equilibrium (given)

Cournot–Nash equilibrium outcomes (given incentives $\theta_i$):

$$
q_i^*=\frac{1}{4}\left(A-c+3\theta_i-\sum_{j\ne i}\theta_j\right)
$$

$$
p^*=\frac{1}{4}\left(A+3c-\sum_i \theta_i\right)
$$

- Interpretation:
  - Increasing $\theta_i$ shifts $q_i^*$ up; rivals’ incentives are strategic substitutes in outputs through $Q$

## Delegation: solving for equilibrium incentives

**Owner’s problem** (taking rivals’ incentives as given):

- Owner maximises profit (not managerial utility):

$$
\max_{\theta_i \ge 0}\ \pi_i^*(\theta_i;\theta_{-i})=\big(p^*(\theta)-c\big)\,q_i^*(\theta)
$$

**First-order condition**:

$$
\frac{\partial \pi_i^*(\theta_i;\theta_{-i})}{\partial \theta_i}=0
$$

- Solving the three FOCs gives a best-response system in $(\theta_1,\theta_2,\theta_3)$
- In symmetry, $\theta_i=\hat{\theta}$ for all $i$, implying $\hat{\theta}=\frac{1}{5}(A-c)$

::: {.notes}
**Full FOC derivation (owner, triopoly):**

Let $\Theta_{-i}=\theta_j+\theta_k$. From the equilibrium expressions:

$$\pi_i^*=\frac{(A-c-\theta_i-\Theta_{-i})(A-c+3\theta_i-\Theta_{-i})}{16}$$

Differentiate with respect to $\theta_i$:

$$\frac{\partial\pi_i^*}{\partial\theta_i}=\frac{1}{16}\Big[-(A-c+3\theta_i-\Theta_{-i})+3(A-c-\theta_i-\Theta_{-i})\Big]=0$$

Expand and collect:

$$2(A-c)-6\theta_i-2\Theta_{-i}=0\quad\Rightarrow\quad\theta_i=\frac{A-c}{3}-\frac{\Theta_{-i}}{3}=\frac{A-c}{3}-\frac{2}{3}\bar{\theta}_{-i}$$

This is the best-response function shown on the next slide. Imposing symmetry $\theta_i=\bar{\theta}_{-i}=\hat{\theta}$:

$$\hat{\theta}=\frac{A-c}{3}-\frac{2}{3}\hat{\theta}\quad\Rightarrow\quad\frac{5}{3}\hat{\theta}=\frac{A-c}{3}\quad\Rightarrow\quad\hat{\theta}=\frac{A-c}{5}$$
:::

## Delegation: best response in incentives (triopoly)

Define the rivals’ average incentive:

$$
\bar{\theta}_{-i}=\frac{1}{n-1}\sum_{j\ne i}\theta_j \quad (n=3)
$$

A reduced-form best response for the owner’s incentive choice can be written as:

$$
\theta_i = BR(\theta_{-i})=\frac{1}{3}(A-c)-\frac{2}{3}\bar{\theta}_{-i}
$$

- Interpretation:
  - Higher rival incentives make rivals more aggressive, reducing the marginal gain from raising $\theta_i$

## Delegation: symmetric equilibrium (fixed point)

In symmetry, $\theta_i=\bar{\theta}_{-i}=\hat{\theta}$ for all $i$.

$$
\hat{\theta}=\frac{1}{3}(A-c)-\frac{2}{3}\hat{\theta}
\quad \Rightarrow \quad
\hat{\theta}=\frac{1}{5}(A-c)
$$

::: {.callout-note}
## What this is doing

This is the standard “best-response fixed point” method: compute $BR(\cdot)$, then impose symmetry.
:::

## Delegation: strategic logic

- **Unilateral incentive**: if rivals set $\theta=0$, choosing $\theta_i>0$ is strictly profitable
  - Positive $\theta_i$ commits the manager to higher output
  - Rivals reduce output (quantities are strategic substitutes)

- **Equilibrium outcome**: all firms choose $\hat{\theta}>0$
  - The strategic advantage disappears when everyone delegates
  - Profits fall: $\hat{\pi}<\pi^C$ (overproduction lowers price for all)

::: {.callout-important}
## Prisoners' dilemma

Each owner's dominant strategy leads to a collectively worse outcome: all firms delegate, output rises, and equilibrium profits fall below the Cournot benchmark.
:::

::: {.callout-note}
## Discussion question

If delegation always lowers industry profits in equilibrium, why would any firm ever choose to delegate? What commitment or regulatory change would allow firms to avoid this outcome?
:::

## Comparison table (triopoly)

| Scenario | Incentives | Per-firm output | Per-firm profit |
|---|---:|---:|---:|
| All delegate | $\hat{\theta}=\frac{A-c}{5}$ | $\hat{q}=\frac{3(A-c)}{10}$ | $\hat{\pi}=\frac{3(A-c)^2}{100}$ |
| None delegate | $\theta=0$ | $q^C=\frac{A-c}{4}$ | $\pi^C=\frac{(A-c)^2}{16}$ |

With $A=10$, $c=1$:

- $\hat{\pi}=2.43$
- $\pi^C=5.0625$

::: {.callout-important}
## Takeaway

Delegation is individually rational in the incentive-setting game but reduces profits in equilibrium.
:::

## Numerical example ($A=10$, $c=1$)

- Parameters: $A=10$, $c=1$

- Delegation equilibrium:
  - $\hat{\theta}=\frac{A-c}{5}=1.8$
  - Per-firm profit: $\hat{\pi}=\frac{3(A-c)^2}{100}=2.43$

- Cournot triopoly benchmark ($\theta_i=0$):
  - Per-firm profit: $\pi^C=\frac{(A-c)^2}{16}=5.0625$

::: {.callout-warning}
## Concrete comparison

With $A=10$, $c=1$: $\hat{\pi}=2.43 < \pi^C=5.0625$ (delegation intensifies competition and lowers profits).
:::

## Delegation: welfare comparison (to Cournot triopoly)

- Delegation increases effective aggressiveness in output:
  - equilibrium price is lower than in standard Cournot triopoly
  - therefore consumer surplus is higher under delegation than under $\theta_i=0$

- Total surplus effect:
  - CS rises due to lower price
  - profits fall due to overproduction relative to joint-profit motives

::: {.callout-note}
## Exam-useful statement

Delegation can be privately attractive ex ante (as a commitment device) but can reduce profits in equilibrium while benefiting consumers.
:::

## Summary and next week

**Summary**

- Subgame perfect equilibrium is solved by backward induction in finite multi-stage games
- Stackelberg timing creates first-mover advantage through commitment
- Strategic delegation can raise aggressiveness but may lower industry profits in equilibrium
- Welfare effects can diverge: consumers may gain even when firms lose

**Next week: cooperative R&D**

- Spillovers and non-cooperative R&D incentives
- Cooperative R&D and research joint ventures
- Welfare and policy implications under different cooperation regimes

## References
